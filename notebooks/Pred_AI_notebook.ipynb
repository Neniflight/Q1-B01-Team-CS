{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b158400",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc7f882",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Import pandas and load training data (the liar dataset from github)\n",
    "import pandas as pd\n",
    "train_data = pd.read_csv('https://raw.githubusercontent.com/Tariq60/LIAR-PLUS/refs/heads/master/dataset/tsv/train2.tsv', sep = \"\\t\")\n",
    "train_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adbce0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column 1: the ID of the statement ([ID].json).\n",
    "# Column 2: the label.\n",
    "# Column 3: the statement.\n",
    "# Column 4: the subject(s).\n",
    "# Column 5: the speaker.\n",
    "# Column 6: the speaker's job title.\n",
    "# Column 7: the state info.\n",
    "# Column 8: the party affiliation.\n",
    "# Columns 9-13: the total credit history count, including the current statement.\n",
    "# 9: barely true counts.\n",
    "# 10: false counts.\n",
    "# 11: half true counts.\n",
    "# 12: mostly true counts.\n",
    "# 13: pants on fire counts.\n",
    "# Column 14: the context (venue / location of the speech or statement).\n",
    "# Column 15: the extracted justification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a2ecb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since there is no column names for this data initially, we kept the column names as our first data to put it back to\n",
    "# the dataframe later\n",
    "first_data = train_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b457c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# naming the columns and adding the first data we extracted back to the end of the dataframe\n",
    "# also droped the index column because it serves the same purpose as the ID of statement column\n",
    "train_data.loc[train_data.shape[0]] = first_data\n",
    "train_data.columns =['index','ID of statement', 'label', 'statement', 'subject', 'speaker', \"speaker's job title\", 'state info',\n",
    "                     'party affiliation', 'barely true counts', 'false counts', 'half true counts', 'mostly true counts',\n",
    "                    'pants on fire counts', 'context', 'extracted justification']\n",
    "train_data = train_data.drop(columns=['index'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980e7687",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e23620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# label -> clean :)\n",
    "# subject -> maybe change str to list\n",
    "# speaker -> clean :)\n",
    "# speaker's job title -> need to fix big and little letters\n",
    "# State info -> clean :)\n",
    "# party affiliation -> clean :)\n",
    "# barely true counts -> not gonna modify\n",
    "# false counts -> not gonna modify\n",
    "# half true counts -> not gonna modify\n",
    "# mostly true counts -> not gonna modify\n",
    "# pants on fire counts -> not gonna modify\n",
    "# context -> assume clean :)\n",
    "# extracted -> str to list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0892a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subject\n",
    "train_data['subject'] = train_data['subject'].str.split(\",\")\n",
    "\n",
    "# speaker's job title\n",
    "train_data[\"speaker's job title\"] = train_data[\"speaker's job title\"].str.lower()\n",
    "\n",
    "# extracted\n",
    "train_data[\"extracted justification\"] = train_data[\"extracted justification\"].str.split(\" \")\n",
    "\n",
    "train_data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9852ae1",
   "metadata": {},
   "source": [
    "## Factuality Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096f4b9",
   "metadata": {},
   "source": [
    "* Social Credibility: People are more likely to perceive a source as credible if others perceive the source is credible\n",
    "* Stance Detection: What is the political or issue stance of the article or text corpus? How does that affect the veracity of the article or text?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc96a3e",
   "metadata": {},
   "source": [
    "#### Social Credibility\n",
    "* Source History: Delve into the past of the post or source to understand its track record\n",
    "* Enforsement checks: a post or source that has been enorsed or validated by external reputable entities gains credibility\n",
    "* revision Analysis: check if the content has been revised updated, or retracted in the past"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d49caaa7",
   "metadata": {},
   "source": [
    "* Basic info:\n",
    "    * 10243 total rows in df\n",
    "    * 4346 types of unique context\n",
    "    * top five context\n",
    "        * a news release                                                  241\n",
    "        * an interview                                                    229\n",
    "        * a press release                                                 223\n",
    "        * a speech                                                        214\n",
    "        * a TV ad                                                         180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa779e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all imports\n",
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn\n",
    "import keras\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder(handle_unknown = \"ignore\", sparse = False)\n",
    "\n",
    "# citation: https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ef5f402",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping null\n",
    "train_data = train_data.dropna()\n",
    "\n",
    "# keeping only 4 columns\n",
    "training_data = train_data[[\"speaker\", \"context\", \"party affiliation\"]]\n",
    "train_label = train_data[['label']]\n",
    "\n",
    "# ohe (data)\n",
    "ohe_label = ohe.fit_transform(np.array(train_label['label']).reshape(-1,1))\n",
    "ohe_label_df = pd.DataFrame(ohe_label, columns = list(train_label['label'].unique()))\n",
    "ohe_speaker = ohe.fit_transform(np.array(training_data['speaker']).reshape(-1,1))\n",
    "ohe_context = ohe.fit_transform(np.array(training_data['context']).reshape(-1,1))\n",
    "ohe_party = ohe.fit_transform(np.array(training_data['party affiliation']).reshape(-1,1))\n",
    "ohe_speaker_ohe_context_ohe_party = []\n",
    "for i in range(len(ohe_speaker)):\n",
    "    ohe_speaker_ohe_context_ohe_party.append(np.concatenate((ohe_speaker[i], ohe_context[i], ohe_party[i])))\n",
    "ohe_speaker_ohe_context_ohe_party = np.array(ohe_speaker_ohe_context_ohe_party)\n",
    "\n",
    "# grouping the ohe of the training data back \n",
    "small_testing_ohe_speaker_context_party_df = pd.DataFrame(ohe_speaker_ohe_context_ohe_party, columns = \n",
    "                                             list(training_data['speaker'].unique()) \n",
    "                                             + list(training_data['context'].unique())\n",
    "                                                + list(training_data['party affiliation'].unique()))\n",
    "\n",
    "\n",
    "# splitting the data into 8:2 for training and testing data\n",
    "training_data = small_testing_ohe_speaker_context_party_df[0: int(small_testing_ohe_speaker_context_party_df.shape[0]*0.8)]\n",
    "training_label = ohe_label_df[0: int(small_testing_ohe_speaker_context_party_df.shape[0]*0.8)]\n",
    "\n",
    "test_data = small_testing_ohe_speaker_context_party_df[int(small_testing_ohe_speaker_context_party_df.shape[0]*0.8):int(small_testing_ohe_speaker_context_party_df.shape[0])]\n",
    "test_label = ohe_label_df[int(small_testing_ohe_speaker_context_party_df.shape[0]*0.8):int(small_testing_ohe_speaker_context_party_df.shape[0])]\n",
    "# citation: https://scikit-learn.org/dev/modules/generated/sklearn.preprocessing.OneHotEncoder.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6fd684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# algorithm/method #1 (keras simple feed forward neural network)\n",
    "from keras.models import Sequential\n",
    "from keras import layers\n",
    "from keras.layers import Dense\n",
    "\n",
    "nn = keras.Sequential([\n",
    "    keras.Input(shape=(training_data.shape[1])),\n",
    "    layers.Dense(10, activation='sigmoid'),\n",
    "    layers.Dense(10, activation='sigmoid'),\n",
    "    layers.Dense(10, activation='sigmoid'),\n",
    "    layers.Dense(6),\n",
    "])\n",
    "\n",
    "nn.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.01), loss = 'mse', metrics = \"accuracy\")\n",
    "\n",
    "nn.fit(training_data, training_label, batch_size = 10, epochs = 100)\n",
    "\n",
    "# citation: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25611ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating predictions for the test data with keras model\n",
    "predictions = nn.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3883b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# since the output of the model is a list with 6 numbers each corresponding to each label\n",
    "# need to find the one with the highest probabiltiy and make that label 1 and others 0\n",
    "cleaned_output = [[1 if pred[i] == max(pred) else 0 for i in range(len(pred))] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5092e7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting the test datset's labels to list for later comparison to check accuracy\n",
    "cleaned_test_label = test_label.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b76e4ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# counting the number of correct predictions\n",
    "correct = 0\n",
    "for i in range(len(cleaned_output)):\n",
    "    if cleaned_output[i] == cleaned_test_label[i]:\n",
    "        correct += 1\n",
    "        \n",
    "correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dda660c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate testing accuracy in percentage\n",
    "correct / len(cleaned_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38c2eae",
   "metadata": {},
   "source": [
    "#### The rest is for other model testing, but we decided to keep the one above since it worked the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e82551",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # algorithm/method #2\n",
    "# nn = keras.Sequential([\n",
    "#     keras.Input(shape=(small_training_ohe_speaker_context_df.shape[1])),\n",
    "#     layers.Dense(10, activation='relu'),\n",
    "#     layers.Dense(10, activation='relu'),\n",
    "#     layers.Dense(10, activation='relu'),\n",
    "#     layers.Dense(6),\n",
    "# ])\n",
    "\n",
    "# nn.compile(optimizer = keras.optimizers.Adam(learning_rate = 0.01), loss = 'mse', metrics = \"accuracy\")\n",
    "\n",
    "# nn.fit(small_training_ohe_speaker_context_df, small_training_ohe_label_df, batch_size = 10, epochs = 50)\n",
    "\n",
    "# # citation: https://keras.io/guides/sequential_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff161027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # algorithm/method #3\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# dt = DecisionTreeClassifier(criterion= \"entropy\", splitter = \"best\")\n",
    "\n",
    "# accuracy = cross_val_score(dt, small_training_ohe_speaker_context_df, small_training_ohe_label_df, cv=5)\n",
    "\n",
    "# accuracy\n",
    "\n",
    "# # citation: https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "# # https://scikit-learn.org/stable/modules/cross_validation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71aee1d9",
   "metadata": {},
   "source": [
    "#### Stance Detection (Political Affiliation) -> will we working on this using GenAI\n",
    "* Language Inspection: Scrutinize content for language indicative or political inclination\n",
    "* Disclosure Checks: Ensure any affiliations by the author or source are openly disclosed\n",
    "* Fact-checker comparison: contrast content claims against neutal, non-partisan fact-checkers"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (clean)",
   "language": "python",
   "name": "python3_clean"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
