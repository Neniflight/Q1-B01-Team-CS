{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "35719d1c-f344-4608-8a03-8bb9ddd1b48b",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df52f075-0ace-4c55-8fe2-600c650e4c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9fdbf1c-2428-4447-b6df-3bd5ad3457fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "scrape_page_num = 20\n",
    "pause_sec = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296b2992-016d-4c53-b411-21cf71f90f1e",
   "metadata": {},
   "source": [
    "### Scrape Latest Fact-checks page (https://www.politifact.com/factchecks/?page=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fac51c7-9d1b-4fcb-9bad-f954c1644269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for later use when adding to chroma\n",
    "politifact_df = pd.DataFrame(columns = ['ID', 'label', 'statement', 'subject', 'speaker', 'speaker_title', 'state', 'party_affliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'extracted_justification'])\n",
    "politifact_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bc44a4-ac91-47b7-a619-166ddf91c2e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# loop through pages of the politifact website\n",
    "for i in range(1,scrape_page_num):\n",
    "    # create temp df for each page\n",
    "    temp_politifact_df = pd.DataFrame(columns = ['ID', 'label', 'statement', 'subject', 'speaker', 'speaker_title', 'state', 'party_affliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'extracted_justification'])\n",
    "\n",
    "    # request and load text\n",
    "    politifac_request = requests.get(\"https://www.politifact.com/factchecks/?page={}\".format(i))\n",
    "    text = BeautifulSoup(politifac_request.text)\n",
    "\n",
    "    # context\n",
    "    context = text.find_all('a', attrs={'class': 'm-statement__name'})\n",
    "    all_context = []\n",
    "    for c in context:\n",
    "        c = c.text\n",
    "        c = c.lower()\n",
    "        c = re.search(\"[a-z]+.{1}[a-z]+\", c)\n",
    "        c = c.group()\n",
    "        all_context.append(c)\n",
    "    \n",
    "    # Statement\n",
    "    statement = text.find_all('div', attrs={'class':'m-statement__quote'})\n",
    "    all_statement = []\n",
    "    for s in statement:\n",
    "        s = s.text\n",
    "        s = s.lower()\n",
    "        s = re.sub(r\"\\s\\s+\",\"\",s)\n",
    "        s = re.sub(r\"[^a-z^\\d^+^ ^.]\",\"\", s)\n",
    "        if s:\n",
    "            all_statement.append(s)\n",
    "        else:\n",
    "            all_statement.append(\"none\")\n",
    "    \n",
    "    # label\n",
    "    label = text.find_all('div', attrs={'class':'m-statement__meter'})\n",
    "    all_label = []\n",
    "    for l in label:\n",
    "        l = l.find('img').get('alt')\n",
    "        all_label.append(l)\n",
    "    \n",
    "    \n",
    "    # author\n",
    "    author = text.find_all('footer', attrs={'class':'m-statement__footer'})\n",
    "    all_author = []\n",
    "    for a in author:\n",
    "        a = a.text\n",
    "        a = a.lower()\n",
    "        a = re.sub(\"by\", \"\", a)\n",
    "        a = re.search(\"[a-z]+.{1}[a-z']+\", a)\n",
    "        a = a.group()\n",
    "        all_author.append(a)\n",
    "\n",
    "    # id\n",
    "    all_id = list(range(len(all_author)))\n",
    "    \n",
    "    # create df\n",
    "    temp_politifact_df['ID'] = all_id\n",
    "    temp_politifact_df['speaker'] = all_author\n",
    "    temp_politifact_df['label'] = all_label\n",
    "    temp_politifact_df['statement'] = all_statement\n",
    "    temp_politifact_df['context'] = all_context\n",
    "    temp_politifact_df['extracted_justification'] = all_statement\n",
    "    \n",
    "    politifact_df = pd.concat([politifact_df, temp_politifact_df], sort=False)\n",
    "    # # sleep\n",
    "    time.sleep(pause_sec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f607ccc-b94f-45b8-b772-c225a5673161",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "politifact_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f7e6894-352b-474b-bbfc-27d5cc5a7b41",
   "metadata": {},
   "source": [
    "### scrape Latest Promises Page (https://www.politifact.com/truth-o-meter/promises/list/?page=1&)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1240e21-c09f-4814-abeb-27e22f6b4bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create df for later use when adding to chroma\n",
    "truth_o_meter_df = pd.DataFrame(columns = ['ID', 'label', 'statement', 'subject', 'speaker', 'speaker_title', 'state', 'party_affliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'extracted_justification'])\n",
    "truth_o_meter_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3bf4661-e061-46c0-86a6-54984eedcfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through pages of the politifact website\n",
    "for i in range(1,scrape_page_num):\n",
    "    # create temp df for each page\n",
    "    temp_truth_o_meter_df = pd.DataFrame(columns = ['ID', 'label', 'statement', 'subject', 'speaker', 'speaker_title', 'state', 'party_affliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'extracted_justification'])\n",
    "\n",
    "    truth_o_meter_request = requests.get(\"https://www.politifact.com/truth-o-meter/promises/list/?page={}&\".format(i))\n",
    "    truth_o_meter_text = BeautifulSoup(truth_o_meter_request.text)\n",
    "\n",
    "    all_truthfulness = []\n",
    "    all_statement = []\n",
    "    all_author = []\n",
    "    all_justification = []\n",
    "    all_id = []\n",
    "    \n",
    "    each_page = truth_o_meter_text.find_all('div', attrs={'class': 'o-listing__item'})\n",
    "\n",
    "    for each_block in each_page:\n",
    "        # get truthfulness\n",
    "        # false -> spectr -> half-true -> true\n",
    "        truthfulness = each_block.find('article').attrs['class'][-1]\n",
    "        truthfulness = truthfulness.replace(\"m-statement--\",\"\")\n",
    "        all_truthfulness.append(truthfulness)\n",
    "        \n",
    "        # get statement\n",
    "        statement = each_block.find('a', attrs={'class': 'm-statement__name'})\n",
    "        statement = statement['title']\n",
    "        all_statement.append(statement)\n",
    "        \n",
    "        # get author\n",
    "        author = each_block.find('a', attrs={'class': 'm-statement__name'})\n",
    "        author = author.text\n",
    "        author = author.lower()\n",
    "        author = re.search(\"[a-z]+.{1}[a-z]+\", author)\n",
    "        author = author.group()\n",
    "        all_author.append(author)\n",
    "        \n",
    "        # get justification\n",
    "        justification = each_block.find('div', attrs = {'class': 'm-statement__quote'})\n",
    "        justification = justification.find('a').text\n",
    "        justification = justification.lower()\n",
    "        justification = re.search(\"[a-z]+.+\", justification)\n",
    "        justification = justification.group()\n",
    "        all_justification.append(justification)\n",
    "    \n",
    "    # get id\n",
    "    id_num = list(range(len(all_author)))\n",
    "    all_id.append(id_num)\n",
    "\n",
    "    # create df\n",
    "    temp_truth_o_meter_df['ID'] = all_id[0]\n",
    "    temp_truth_o_meter_df['speaker'] = all_author\n",
    "    temp_truth_o_meter_df['label'] = all_truthfulness\n",
    "    temp_truth_o_meter_df['statement'] = all_statement\n",
    "    temp_truth_o_meter_df['extracted_justification'] = all_justification\n",
    "    \n",
    "    truth_o_meter_df = pd.concat([truth_o_meter_df, temp_truth_o_meter_df], sort=False)\n",
    "    # sleep\n",
    "    time.sleep(pause_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b191673-b375-416d-aadb-893252b19ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "truth_o_meter_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3e7104-180a-4d13-a5d5-ad7e915785b8",
   "metadata": {},
   "source": [
    "### merge the two df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7eebf-518f-45c1-a341-3665181bcb98",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_df = pd.concat([politifact_df, truth_o_meter_df], ignore_index=True)\n",
    "final_df['ID'] = final_df.index\n",
    "final_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc32165-67b1-4856-966a-6122c94031db",
   "metadata": {},
   "source": [
    "### Add both dataframe to chormadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3423d5b2-04f5-4420-8d68-9bc8dca77dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504da7e9-0e48-48dc-a97a-ad657f03ae94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "chroma_client = chromadb.HttpClient(host='localhost', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb325b65-600c-495a-ab53-9e45ef3c0367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preprocessing\n",
    "train_data = final_df\n",
    "train_data.columns = ['ID', 'label', 'statement', 'subject', 'speaker', 'speaker_title', 'state', 'party_affliation', 'barely_true_counts', 'false_counts', 'half_true_counts', 'mostly_true_counts', 'pants_on_fire_counts', 'context', 'extracted_justification']\n",
    "train_data = train_data[(train_data['speaker'].notna()) & (train_data['label'].notna())].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe769af-5c67-48ed-a2bb-6dee80ada3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get chroma client\n",
    "collection = chroma_client.get_or_create_collection(name=\"Misinformation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf4d35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if else statement to prevent adding same doc to docker if distances == 0\n",
    "all_statements = train_data['statement']\n",
    "for i in range(train_data.shape[0]):\n",
    "    dist = collection.query(query_texts=[all_statements[i]], n_results=1)\n",
    "    dist = dist[\"distances\"][0][0]\n",
    "    if dist == 0:\n",
    "        train_data = train_data.drop([i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd65da29-4018-42de-895b-99498025c9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# put non-repetitive data into documents, metadatas, ids lists.\n",
    "documents = []\n",
    "metadatas = []\n",
    "ids = []\n",
    "prev_df_size = collection.count()\n",
    "prev_df_plus_politifact_df_size = train_data.shape[0] + prev_df_size\n",
    "for i in range(prev_df_size, prev_df_plus_politifact_df_size):\n",
    "    documents.append(train_data.loc[i - prev_df_size, 'statement'])\n",
    "    metadatas.append({\"label\": train_data.loc[i - prev_df_size, 'label'], \"speaker\": train_data.loc[i - prev_df_size, \"speaker\"], \"party_affliation\": train_data.loc[i - prev_df_size, \"party_affliation\"], \"justification\": train_data.loc[i - prev_df_size, \"extracted_justification\"], })\n",
    "    ids.append(\"id\" + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57839d6d-66e5-4632-be80-a42bb6102196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add those data to collection\n",
    "collection.add(documents = documents, \n",
    "               metadatas=metadatas, \n",
    "               ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7702a3-043c-427c-b6ed-004283688ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query to ensure it works! Returns top 3 closest statements from our data to the text imputted!\n",
    "results = collection.query(query_texts=[\"Promise Kept: Planned Parenthood regained fede\"], \n",
    "                 n_results=3,\n",
    "               #   where=\n",
    "               #   {\n",
    "               #      \"label\": \"true\"\n",
    "               #   })\n",
    ")\n",
    "print(results['documents'])\n",
    "print(results[\"distances\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d2bccb-3d6a-4aac-ba49-757b4c382071",
   "metadata": {},
   "source": [
    "### Citation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269e2bd3-b6f3-4b8f-9005-62973986b7c9",
   "metadata": {},
   "source": [
    "https://www.w3schools.com/python/python_regex.asp\n",
    "\n",
    "https://github.com/srcole/politifact-analysis/blob/master/Politifact%20-%201a%20-%20scrape%20fact%20check%20data.ipynb\n",
    "\n",
    "https://www.geeksforgeeks.org/extracting-an-attribute-value-with-beautifulsoup-in-python/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
