{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold, content_types\n",
    "from collections.abc import Iterable\n",
    "from function_calls import final_factuality_factor_score, emotion_analyzer\n",
    "from poli_stance_function_calling import perspective_analyzer\n",
    "from google.protobuf.struct_pb2 import Struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://github.com/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/function-calling/python.ipynb, https://github.com/google-gemini/cookbook/blob/main/quickstarts/Function_calling.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = {\n",
    "#   \"functions\": [\n",
    "#       {\n",
    "#         \"name\": \"emotion_analyzer\",\n",
    "#         \"description\": \"Analyzes the emotionality and exaggeration level in a given text and returns a scaled score.\",\n",
    "#         \"parameters\": {\n",
    "#           \"type\": \"object\",\n",
    "#           \"properties\": {\n",
    "#             \"text\": {\n",
    "#               \"type\": \"string\",\n",
    "#               \"description\": \"The text content to analyze for emotional intensity and exaggeration.\"\n",
    "#             }\n",
    "#           },\n",
    "#           \"required\": [\"text\"]\n",
    "#         }\n",
    "#       },\n",
    "#       {\n",
    "#         \"name\": \"final_factuality_factor_score\",\n",
    "#         \"description\": \"Averages the microfactors from a single factuality factor. This function should be used when combining into an overall score.\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"microfactor_1\": {\n",
    "#                     \"type\": \"float\",\n",
    "#                     \"description\": \"First microfactor for a factuality factor, used to help calculate the factuality factor\"\n",
    "#                 },\n",
    "#                 \"microfactor_2\": {\n",
    "#                     \"type\": \"float\",\n",
    "#                     \"description\": \"Second microfactor for a factuality factor, used to help calculate the factuality factor\"\n",
    "#                 },\n",
    "#                 \"microfactor_3\": {\n",
    "#                     \"type\": \"float\",\n",
    "#                     \"description\": \"Third microfactor for a factuality factor, used to help calculate the factuality factor\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"microfactor_1\", \"microfactor_2\", \"microfactor_3\"]\n",
    "#         }\n",
    "#       }\n",
    "#   ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment function calling part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"max_output_tokens\": 4000, # less output, means faster\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "    \"temperature\": 1, # higher temp --> more risks the model takes with choices\n",
    "    \"top_p\": 0.95, # how many tokens are considered when producing outputs\n",
    "    \"top_k\": 40, # token is selected from 40 likely tokens\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "  HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )\n",
    "\n",
    "functions = {\"final_factuality_factor_score\": final_factuality_factor_score,\n",
    "            \"emotion_analyzer\": emotion_analyzer,}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-002\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    "    tools = functions.values(),\n",
    "    system_instruction=\"\"\"\n",
    "        You are trying to fight against misinformation by scoring different articles on their factuality factors. \n",
    "        In your responses:\n",
    "        - Use each function only once per request.\n",
    "        - Integrate the results from the function calls to generate a complete response.\n",
    "        - Do not assess an article until you are given a factuality factor to grade on.\n",
    "        - Be concise and avoid redundant function calls.    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = model.start_chat(enable_automatic_function_calling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chat.send_message(\"\"\"\n",
    "# \"Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.\"\n",
    "# Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\n",
    "# 1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\n",
    "# 2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\n",
    "# 3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\n",
    "# Then, combine them into an overall score for sensationalism and explain your thought process.\n",
    "# Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\n",
    "# \"\"\")\n",
    "# print(f\"Model response: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(function_call, functions):\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "    return functions[function_name](**function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_generate_content(input):\n",
    "    response = model.generate_content(input, tool_config=tool_config)\n",
    "    parts = response.candidates[0].content.parts\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"parts\": [input]})\n",
    "    for part in parts:\n",
    "        if part.function_call:\n",
    "            result = call_function(part.function_call, functions)\n",
    "            s = Struct()\n",
    "            s.update({\"result\": result})\n",
    "            function_response = genai.protos.Part(\n",
    "                function_response=genai.protos.FunctionResponse(name=part.function_call.name, response=s)\n",
    "            )\n",
    "            messages.append({\"role\": \"model\", \"parts\": [part]})\n",
    "            messages.append({\"role\": \"user\", \"parts\": [function_response]})\n",
    "        else:\n",
    "            messages.append({\"role\": \"model\", \"parts\": [part.text]})\n",
    "                # fmt: off\n",
    "            #     {\"role\": \"user\",\n",
    "            #     \"parts\": [\"'Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.'\\\n",
    "            # Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\\\n",
    "            # 1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\\\n",
    "            # 2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "            # 3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\\\n",
    "            # Then, combine them into an overall score for sensationalism and explain your thought process.\\\n",
    "            # Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\"]},\n",
    "            #     {\"role\": \"model\",\n",
    "            #     \"parts\": response.candidates[0].content.parts},\n",
    "            #     {\"role\": \"user\",\n",
    "            #     \"parts\": [function_response]},\n",
    "            #     # fmt: on\n",
    "    print(messages)\n",
    "    new_response = model.generate_content(messages)\n",
    "    return new_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = fc_generate_content(\"'Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.'\\\n",
    "Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\\\n",
    "1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\\\n",
    "2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\\\n",
    "Then, combine them into an overall score for sensationalism and explain your thought process.\\\n",
    "Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\")\n",
    "# break down prompt and split into different intentions, intention: {}\n",
    "# distinguish between each chunk, each chunk has a header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Political stance function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"max_output_tokens\": 4000, # less output, means faster\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "    \"temperature\": 1, # higher temp --> more risks the model takes with choices\n",
    "    \"top_p\": 0.95, # how many tokens are considered when producing outputs\n",
    "    \"top_k\": 40, # token is selected from 40 likely tokens\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "  HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )\n",
    "\n",
    "functions = {\"final_factuality_factor_score\": final_factuality_factor_score,\n",
    "            \"emotion_analyzer\": emotion_analyzer,\n",
    "            \"perspective_analyzer\": perspective_analyzer}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-002\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    "    tools = functions.values(),\n",
    "    system_instruction=\"\"\"\n",
    "        You are trying to fight against misinformation by scoring different articles on their factuality factors. \n",
    "        In your responses:\n",
    "        - Use each function only once per request.\n",
    "        - Integrate the results from the function calls to generate a complete response.\n",
    "        - Do not assess an article until you are given a factuality factor to grade on.\n",
    "        - Be concise and avoid redundant function calls.    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(function_call, functions):\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "    return functions[function_name](**function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fc_generate_content(input):\n",
    "    response = model.generate_content(input, tool_config=tool_config)\n",
    "    parts = response.candidates[0].content.parts\n",
    "    messages = []\n",
    "    messages.append({\"role\": \"user\", \"parts\": [input]})\n",
    "    for part in parts:\n",
    "        if part.function_call:\n",
    "            result = call_function(part.function_call, functions)\n",
    "            s = Struct()\n",
    "            s.update({\"result\": result})\n",
    "            function_response = genai.protos.Part(\n",
    "                function_response=genai.protos.FunctionResponse(name=part.function_call.name, response=s)\n",
    "            )\n",
    "            messages.append({\"role\": \"model\", \"parts\": [part]})\n",
    "            messages.append({\"role\": \"user\", \"parts\": [function_response]})\n",
    "        else:\n",
    "            messages.append({\"role\": \"model\", \"parts\": [part.text]})\n",
    "                # fmt: off\n",
    "            #     {\"role\": \"user\",\n",
    "            #     \"parts\": [\"'Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.'\\\n",
    "            # Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\\\n",
    "            # 1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\\\n",
    "            # 2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "            # 3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\\\n",
    "            # Then, combine them into an overall score for sensationalism and explain your thought process.\\\n",
    "            # Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\"]},\n",
    "            #     {\"role\": \"model\",\n",
    "            #     \"parts\": response.candidates[0].content.parts},\n",
    "            #     {\"role\": \"user\",\n",
    "            #     \"parts\": [function_response]},\n",
    "            #     # fmt: on\n",
    "    print(messages)\n",
    "    new_response = model.generate_content(messages)\n",
    "    return new_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = fc_generate_content(\"'Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.'\\\n",
    "Given the previous sentence, rate the sentence based on political stance with 1 being extremely biased towards democratic and \\\n",
    "10 being extremely biased towards conservative and 5 being neutral from a score of 1 to 10. \\\n",
    "First, rate the setence on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, \\\n",
    "ensuring that you explain the reasoning behind each score, and feel free to use function calling:\\\n",
    "1. Perspective Analysis: Identify underlying perspectives on issues or events. \\\n",
    "2. Bias evaluation: Evaluate if the stance is consistently biased. \\\n",
    "3. verify facts: Compare the stance against verified facts. This should be done paragraph by paragraph. \\\n",
    "Then, combine them into an overall score for a political stance. Lastly please phrase the overall score as 'Normal Prompting Overall Stance: {score}' \\\n",
    ", where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\")\n",
    "# break down prompt and split into different intentions, intention: {}\n",
    "# distinguish between each chunk, each chunk has a header "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
