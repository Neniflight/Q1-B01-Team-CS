{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunking Notebook\n",
    "This notebook is chunking the website where each chunk is the line that each speaker says in the article. Unfortunately, some parts of this interview has false statements. This is the first part of our LLM AI for misinformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests \n",
    "from bs4 import BeautifulSoup\n",
    "import regex as re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using a test article, getting the soup for it\n",
    "article_URL = \"https://www.npr.org/transcripts/153705721\"\n",
    "page = requests.get(article_URL)\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only the first p-tag has useful information we want, so we index to first element\n",
    "p_tags = soup.find_all(\"p\", id=False, class_=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we replace newline characters and information within parentheses with blanks\n",
    "interview_text = re.sub(r\"\\n|\\(.+\\)\", \"\", p_tags[0].find(\"p\").get_text()).replace(\"\\\\'\", \"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we split the article into chunks where we split on the condiiton of \".{any capital letter}\"\n",
    "lines = re.split(r\"\\.(?=[A-Z])|\\?(?=[A-Z])\", interview_text)[:-2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List saved successfully as a pickle file.\n"
     ]
    }
   ],
   "source": [
    "# save as pickle file for use later\n",
    "with open('data/chunks.pkl', 'wb') as file:\n",
    "    pickle.dump(lines, file)\n",
    "print(\"List saved successfully as a pickle file.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are interested in extracting the chunks, use the code block below to do so. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('data/chunks.pkl', 'rb') as file:\n",
    "#     loaded_lines = pickle.load(file)\n",
    "# loaded_lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
