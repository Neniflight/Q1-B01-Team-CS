{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold, content_types\n",
    "from collections.abc import Iterable\n",
    "from function_calls import final_factuality_factor_score, emotion_analyzer\n",
    "from google.protobuf.struct_pb2 import Struct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Documentation: https://github.com/google/generative-ai-docs/blob/main/site/en/gemini-api/docs/function-calling/python.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tools = {\n",
    "#   \"functions\": [\n",
    "#       {\n",
    "#         \"name\": \"emotion_analyzer\",\n",
    "#         \"description\": \"Analyzes the emotionality and exaggeration level in a given text and returns a scaled score.\",\n",
    "#         \"parameters\": {\n",
    "#           \"type\": \"object\",\n",
    "#           \"properties\": {\n",
    "#             \"text\": {\n",
    "#               \"type\": \"string\",\n",
    "#               \"description\": \"The text content to analyze for emotional intensity and exaggeration.\"\n",
    "#             }\n",
    "#           },\n",
    "#           \"required\": [\"text\"]\n",
    "#         }\n",
    "#       },\n",
    "#       {\n",
    "#         \"name\": \"final_factuality_factor_score\",\n",
    "#         \"description\": \"Averages the microfactors from a single factuality factor. This function should be used when combining into an overall score.\",\n",
    "#         \"parameters\": {\n",
    "#             \"type\": \"object\",\n",
    "#             \"properties\": {\n",
    "#                 \"microfactor_1\": {\n",
    "#                     \"type\": \"float\",\n",
    "#                     \"description\": \"First microfactor for a factuality factor, used to help calculate the factuality factor\"\n",
    "#                 },\n",
    "#                 \"microfactor_2\": {\n",
    "#                     \"type\": \"float\",\n",
    "#                     \"description\": \"Second microfactor for a factuality factor, used to help calculate the factuality factor\"\n",
    "#                 },\n",
    "#                 \"microfactor_3\": {\n",
    "#                     \"type\": \"float\",\n",
    "#                     \"description\": \"Third microfactor for a factuality factor, used to help calculate the factuality factor\"\n",
    "#                 }\n",
    "#             },\n",
    "#             \"required\": [\"microfactor_1\", \"microfactor_2\", \"microfactor_3\"]\n",
    "#         }\n",
    "#       }\n",
    "#   ]\n",
    "# }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"max_output_tokens\": 4000, # less output, means faster\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "    \"temperature\": 1, # higher temp --> more risks the model takes with choices\n",
    "    \"top_p\": 0.95, # how many tokens are considered when producing outputs\n",
    "    \"top_k\": 40, # token is selected from 40 likely tokens\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "  HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )\n",
    "\n",
    "functions = {\"final_factuality_factor_score\": final_factuality_factor_score,\n",
    "            \"emotion_analyzer\": emotion_analyzer,}\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-002\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    "    tools = functions.values(),\n",
    "    system_instruction=\"\"\"\n",
    "        You are trying to fight against misinformation by scoring different articles on their factuality factors. \n",
    "        In your responses:\n",
    "        - Use each function only once per request.\n",
    "        - Integrate the results from the function calls to generate a complete response.\n",
    "        - Do not assess an article until you are given a factuality factor to grade on.\n",
    "        - Be concise and avoid redundant function calls.    \n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chat = model.start_chat(enable_automatic_function_calling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# response = chat.send_message(\"\"\"\n",
    "# \"Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.\"\n",
    "# Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\n",
    "# 1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\n",
    "# 2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\n",
    "# 3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\n",
    "# Then, combine them into an overall score for sensationalism and explain your thought process.\n",
    "# Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\n",
    "# \"\"\")\n",
    "# print(f\"Model response: {response.text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_function(function_call, functions):\n",
    "    function_name = function_call.name\n",
    "    function_args = function_call.args\n",
    "    return functions[function_name](**function_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[text: \"Here\\'s an analysis of the sentence based on the sensationalism factor:\\n\\n1. **Sensationalism Detection:** The phrase \\\"Shocking Discovery\\\" and \\\"Change Humanity Forever\\\" are clear indicators of sensationalism. It uses hyperbole to grab attention and create a sense of urgency.  I would score this a 9/10.\\n\\n2. **Emotion Analysis:** Let\\'s analyze the sentence\\'s emotionality using the `emotion_analyzer` function:\\n\\n\"\n",
       ", function_call {\n",
       "  name: \"emotion_analyzer\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"text\"\n",
       "      value {\n",
       "        string_value: \"Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.\"\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", text: \"\\n\\nI\\'ll incorporate the result of this function call once you provide it.\\n\\n3. **Linguistic Database Comparison:**  This requires comparing the sentence\\'s phrasing and vocabulary against known patterns in reliable and unreliable sources. Since I don\\'t have access to such a database, I\\'ll make an educated guess. The exaggerated claims and dramatic tone resemble typical clickbait language, often found in less credible sources. Therefore, I\\'ll score this an 8/10.\\n\\nNow, let\\'s combine these scores. Assuming the `emotion_analyzer` returns a score of 8, we can calculate the overall score:\\n\\n\"\n",
       ", function_call {\n",
       "  name: \"final_factuality_factor_score\"\n",
       "  args {\n",
       "    fields {\n",
       "      key: \"microfactor_3\"\n",
       "      value {\n",
       "        number_value: 8\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"microfactor_2\"\n",
       "      value {\n",
       "        number_value: 8\n",
       "      }\n",
       "    }\n",
       "    fields {\n",
       "      key: \"microfactor_1\"\n",
       "      value {\n",
       "        number_value: 9\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       ", text: \"\\n\\nOnce you provide the result of this function call, I\\'ll give you the final answer in the requested format.\\n\"\n",
       "]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "response = model.generate_content(\n",
    "    \"'Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.'\\\n",
    "Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\\\n",
    "1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\\\n",
    "2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\\\n",
    "Then, combine them into an overall score for sensationalism and explain your thought process.\\\n",
    "Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\", tool_config=tool_config)\n",
    "response.candidates[0].content.parts\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "response:\n",
       "GenerateContentResponse(\n",
       "    done=True,\n",
       "    iterator=None,\n",
       "    result=protos.GenerateContentResponse({\n",
       "      \"candidates\": [\n",
       "        {\n",
       "          \"content\": {\n",
       "            \"parts\": [\n",
       "              {\n",
       "                \"text\": \"Here's an analysis of the sentence based on the sensationalism factor:\\n\\n1. **Sensationalism Detection:** The phrase \\\"Shocking Discovery\\\" and \\\"Change Humanity Forever\\\" are clear indicators of sensationalism. It uses hyperbole to grab attention and create a sense of urgency.  I would score this a 9/10.\\n\\n2. **Emotion Analysis:** Let's analyze the sentence's emotionality using the `emotion_analyzer` function:\\n\\n\"\n",
       "              },\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"emotion_analyzer\",\n",
       "                  \"args\": {\n",
       "                    \"text\": \"Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.\"\n",
       "                  }\n",
       "                }\n",
       "              },\n",
       "              {\n",
       "                \"text\": \"\\n\\nI'll incorporate the result of this function call once you provide it.\\n\\n3. **Linguistic Database Comparison:**  This requires comparing the sentence's phrasing and vocabulary against known patterns in reliable and unreliable sources. Since I don't have access to such a database, I'll make an educated guess. The exaggerated claims and dramatic tone resemble typical clickbait language, often found in less credible sources. Therefore, I'll score this an 8/10.\\n\\nNow, let's combine these scores. Assuming the `emotion_analyzer` returns a score of 8, we can calculate the overall score:\\n\\n\"\n",
       "              },\n",
       "              {\n",
       "                \"function_call\": {\n",
       "                  \"name\": \"final_factuality_factor_score\",\n",
       "                  \"args\": {\n",
       "                    \"microfactor_1\": 9.0,\n",
       "                    \"microfactor_2\": 8.0,\n",
       "                    \"microfactor_3\": 8.0\n",
       "                  }\n",
       "                }\n",
       "              },\n",
       "              {\n",
       "                \"text\": \"\\n\\nOnce you provide the result of this function call, I'll give you the final answer in the requested format.\\n\"\n",
       "              }\n",
       "            ],\n",
       "            \"role\": \"model\"\n",
       "          },\n",
       "          \"finish_reason\": \"STOP\",\n",
       "          \"safety_ratings\": [\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HATE_SPEECH\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_HARASSMENT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            },\n",
       "            {\n",
       "              \"category\": \"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
       "              \"probability\": \"NEGLIGIBLE\"\n",
       "            }\n",
       "          ],\n",
       "          \"avg_logprobs\": -0.14057995521858946\n",
       "        }\n",
       "      ],\n",
       "      \"usage_metadata\": {\n",
       "        \"prompt_token_count\": 578,\n",
       "        \"candidates_token_count\": 292,\n",
       "        \"total_token_count\": 870\n",
       "      }\n",
       "    }),\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name: \"final_factuality_factor_score\"\n",
       "args {\n",
       "  fields {\n",
       "    key: \"microfactor_3\"\n",
       "    value {\n",
       "      number_value: 8\n",
       "    }\n",
       "  }\n",
       "  fields {\n",
       "    key: \"microfactor_2\"\n",
       "    value {\n",
       "      number_value: 8\n",
       "    }\n",
       "  }\n",
       "  fields {\n",
       "    key: \"microfactor_1\"\n",
       "    value {\n",
       "      number_value: 9\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# change the index after parts to update the function call\n",
    "response.candidates[0].content.parts[3].function_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.17\n"
     ]
    }
   ],
   "source": [
    "part = response.candidates[0].content.parts[0]\n",
    "\n",
    "if part.function_call:\n",
    "    result = call_function(part.function_call, functions)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = response.candidates[1].content.parts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Struct()\n",
    "s.update({\"result\": result})\n",
    "\n",
    "function_response = genai.protos.Part(\n",
    "    function_response=genai.protos.FunctionResponse(name=response.candidates[0].content.parts[0].function_call.name, response=s)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    # fmt: off\n",
    "    {\"role\": \"user\",\n",
    "     \"parts\": [\"'Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!.'\\\n",
    "Given the previous sentence, rate the sentence based on the defined microfactors of the factuality factor, sensationalism, from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling:\\\n",
    "1. Sensationalism Detection: Identify instancesS of sensationalism in titles and main content.\\\n",
    "2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "3. Linguistic Database Comparison: Match linguistic features against databases of both trusted and untrusted sources to ascertain reliability.\\\n",
    "Then, combine them into an overall score for sensationalism and explain your thought process.\\\n",
    "Lastly, please phrase the overall score as 'Normal Prompting Overall sensationalism: {score}', where score is calculated via the final_factuality_factor_score function. Each function call should be used once.\"]},\n",
    "    {\"role\": \"model\",\n",
    "     \"parts\": response.candidates[0].content.parts},\n",
    "    {\"role\": \"user\",\n",
    "     \"parts\": [function_response]},\n",
    "    # fmt: on\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 * GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 * GenerateContentRequest.contents[2].parts[0].function_response.name: Name cannot be empty.\n"
     ]
    }
   ],
   "source": [
    "response = model.generate_content(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "candidates {\n",
       "  content {\n",
       "    parts {\n",
       "      text: \"1. **Sensationalism Detection:** The title uses strong emotional language (\\\"Shocking,\\\" \\\"Secret,\\\" \\\"Change Humanity Forever\\\") and lacks specific details, suggesting a high degree of sensationalism. **Score: 9/10**\\n\\n2. **Emotion Analysis:** The title evokes strong emotions like surprise and excitement but does not contain factual information.  The provided `emotion_analyzer` function output further supports a moderate level of emotionality. **Score: 5.17/10**\\n\\n3. **Linguistic Database Comparison:** While I lack access to external databases to perform a direct comparison, the linguistic features (hyperbole, grand claims) are commonly associated with less trustworthy sources.  **Score: 8/10**\\n\\nTo calculate the overall sensationalism score, I\\'ll use the provided function:\\n\\n\"\n",
       "    }\n",
       "    parts {\n",
       "      function_call {\n",
       "        name: \"final_factuality_factor_score\"\n",
       "        args {\n",
       "          fields {\n",
       "            key: \"microfactor_3\"\n",
       "            value {\n",
       "              number_value: 8\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"microfactor_2\"\n",
       "            value {\n",
       "              number_value: 5.17\n",
       "            }\n",
       "          }\n",
       "          fields {\n",
       "            key: \"microfactor_1\"\n",
       "            value {\n",
       "              number_value: 9\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      }\n",
       "    }\n",
       "    role: \"model\"\n",
       "  }\n",
       "  finish_reason: STOP\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HATE_SPEECH\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_HARASSMENT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  safety_ratings {\n",
       "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
       "    probability: NEGLIGIBLE\n",
       "  }\n",
       "  avg_logprobs: -0.23600547351138129\n",
       "}\n",
       "usage_metadata {\n",
       "  prompt_token_count: 628\n",
       "  candidates_token_count: 191\n",
       "  total_token_count: 819\n",
       "}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response._result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
