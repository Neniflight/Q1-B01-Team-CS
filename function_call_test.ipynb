{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import google.generativeai as genai\n",
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold, content_types\n",
    "from collections.abc import Iterable\n",
    "from function_calls import emotionality_analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"API_KEY\")\n",
    "genai.configure(api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = {\n",
    "  \"name\": \"emotionality_analyzer\",\n",
    "  \"description\": \"Analyzes the emotionality and exaggeration level in a given text and returns a scaled score.\",\n",
    "  \"parameters\": {\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "      \"text\": {\n",
    "        \"type\": \"string\",\n",
    "        \"description\": \"The text content to analyze for emotional intensity and exaggeration.\"\n",
    "      }\n",
    "    },\n",
    "    \"required\": [\"text\"]\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"max_output_tokens\": 4000, # less output, means faster\n",
    "    \"response_mime_type\": \"text/plain\",\n",
    "    \"temperature\": 1, # higher temp --> more risks the model takes with choices\n",
    "    \"top_p\": 0.95, # how many tokens are considered when producing outputs\n",
    "    \"top_k\": 40, # token is selected from 40 likely tokens\n",
    "}\n",
    "\n",
    "safety_settings = {\n",
    "  HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,\n",
    "  HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,\n",
    "}\n",
    "\n",
    "def tool_config_from_mode(mode: str, fns: Iterable[str] = ()):\n",
    "    \"\"\"Create a tool config with the specified function calling mode.\"\"\"\n",
    "    return content_types.to_tool_config(\n",
    "        {\"function_calling_config\": {\"mode\": mode, \"allowed_function_names\": fns}}\n",
    "    )\n",
    "\n",
    "functions = [emotionality_analyzer]\n",
    "\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-1.5-pro-002\",\n",
    "    generation_config=generation_config,\n",
    "    safety_settings=safety_settings,\n",
    "    tools = functions,\n",
    "    system_instruction=\"You are trying to fight against misinformation by scoring different articles on their factuality factors. In your responses, do not use copyrighted material and be concise. Do not assess an article until you are given a factuality factor to grade on.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_config = {\n",
    "    \"function_calling_config\": {\n",
    "        \"mode\": \"AUTO\", \n",
    "        \"allowed_function_names\": [\"emotionality_analyzer\"]\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = model.start_chat(enable_automatic_function_calling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "emotionalaity_score: 4.3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'1. **Sensationalism Detection (9/10):** The title uses strong emotional language (\"Shocking,\" \"Secret,\" \"Change Humanity Forever\") which are common sensationalist tactics.  The claim is also very broad and lacks specifics.\\n\\n2. **Emotion Analysis (10/10):**  The title is designed to evoke strong emotions (shock, excitement, anticipation) without providing any factual basis. The exaggeration is evident in the claim of changing humanity forever.\\n\\n3. **Linguistic Database Comparison (Not Applicable/10):** I lack the functionality to compare the text against databases of reliable/unreliable sources.\\n\\nNormal Prompting Overall sensationalism: 4.3\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chat.send_message(\"Shocking Discovery: Scientists Unveil a Secret That Will Change Humanity Forever!. \\\n",
    "Given the previous sentence, rate the sentence based on the defined microfactors of sensationalism from 1 to 10, ensuring that you explain the reasoning behind each score, and feel free to use function calling: \\\n",
    "1. Sensationalism Detection: Identify instances of sensationalism in titles and main content. \\\n",
    "2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "3. Linguistic Database Comparison: Match linguistic features against databases of both \\\n",
    "trusted and untrusted sources to ascertain reliability.\\\n",
    "Then, combine them into an overall score for sensationalism.\\\n",
    "Lastly please phrase overall score as 'Normal Prompting Overall sensationalism: {score}'\\\n",
    "where score is a float and the phrase should be in plain text with no bolding or italics\")\n",
    "response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'object'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\marshal\\rules\\message.py:36\u001b[0m, in \u001b[0;36mMessageRule.to_proto\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# Try the fast path first.\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_descriptor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# If we have a TypeError or Valueerror,\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# try the slow path in case the error\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m#   See related issue: https://github.com/googleapis/python-api-core/issues/227.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     \u001b[38;5;66;03m# - a missing key issue due to nested struct. See: b/321905145.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Protocol message Schema has no \"type\" field.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# tool_config = tool_config_from_mode(\"auto\")\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mGiven the inputted article rate it based on sensationalism from a score of 1 to 10.\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;43mFirst, rate each chunk of the article based on the defined microfactors of sensationalism: \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;43m1. Sensationalism Detection: Identify instances of sensationalism in titles and main content. \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124;43m2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124;43m3. Linguistic Database Comparison: Match linguistic features against databases of both \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124;43mtrusted and untrusted sources to ascertain reliability.\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124;43mThis should be done paragraph by paragraph. \u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124;43mThen, combine them into an overall score for sensationalism.\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;43mLastly please phrase overall score as \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNormal Prompting Overall sensationalism: \u001b[39;49m\u001b[38;5;132;43;01m{score}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\\u001b[39;49;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;43mwhere score is a float and the phrase should be in plain text with no bolding or italics\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m response:\n\u001b[0;32m     14\u001b[0m     text_chunk \u001b[38;5;241m=\u001b[39m chunk\u001b[38;5;241m.\u001b[39mtext\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\generative_models.py:305\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    302\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m contents:\n\u001b[0;32m    303\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontents must not be empty\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 305\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    306\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcontents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    307\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    308\u001b[0m \u001b[43m    \u001b[49m\u001b[43msafety_settings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msafety_settings\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    309\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    310\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtool_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtool_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    311\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole:\n\u001b[0;32m    314\u001b[0m     request\u001b[38;5;241m.\u001b[39mcontents[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mrole \u001b[38;5;241m=\u001b[39m _USER_ROLE\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\generative_models.py:145\u001b[0m, in \u001b[0;36mGenerativeModel._prepare_request\u001b[1;34m(self, contents, generation_config, safety_settings, tools, tool_config)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cached_content\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_system_instruction, tools, tool_config]):\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tools`, `tool_config`, `system_instruction` cannot be set on a model instantiated with `cached_content` as its context.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    143\u001b[0m     )\n\u001b[1;32m--> 145\u001b[0m tools_lib \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_tools_lib\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tools_lib \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    147\u001b[0m     tools_lib \u001b[38;5;241m=\u001b[39m tools_lib\u001b[38;5;241m.\u001b[39mto_proto()\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\generative_models.py:182\u001b[0m, in \u001b[0;36mGenerativeModel._get_tools_lib\u001b[1;34m(self, tools)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tools\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontent_types\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_function_library\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:903\u001b[0m, in \u001b[0;36mto_function_library\u001b[1;34m(lib)\u001b[0m\n\u001b[0;32m    901\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\n\u001b[0;32m    902\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFunctionLibrary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlib\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:841\u001b[0m, in \u001b[0;36mFunctionLibrary.__init__\u001b[1;34m(self, tools)\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, tools: Iterable[ToolType]):\n\u001b[1;32m--> 841\u001b[0m     tools \u001b[38;5;241m=\u001b[39m \u001b[43m_make_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    842\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tools \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(tools)\n\u001b[0;32m    843\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_index \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:891\u001b[0m, in \u001b[0;36m_make_tools\u001b[1;34m(tools)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    890\u001b[0m     tool \u001b[38;5;241m=\u001b[39m tools\n\u001b[1;32m--> 891\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43m_make_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m)\u001b[49m]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\google\\generativeai\\types\\content_types.py:809\u001b[0m, in \u001b[0;36m_make_tool\u001b[1;34m(tool)\u001b[0m\n\u001b[0;32m    807\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    808\u001b[0m         fd \u001b[38;5;241m=\u001b[39m tool\n\u001b[1;32m--> 809\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Tool(function_declarations\u001b[38;5;241m=\u001b[39m[\u001b[43mprotos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFunctionDeclaration\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfd\u001b[49m\u001b[43m)\u001b[49m])\n\u001b[0;32m    810\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tool, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    811\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tool\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode_execution\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\message.py:728\u001b[0m, in \u001b[0;36mMessage.__init__\u001b[1;34m(self, mapping, ignore_unknown_fields, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown field for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, key)\n\u001b[0;32m    726\u001b[0m     )\n\u001b[1;32m--> 728\u001b[0m pb_value \u001b[38;5;241m=\u001b[39m \u001b[43mmarshal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpb_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     params[key] \u001b[38;5;241m=\u001b[39m pb_value\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\marshal\\marshal.py:235\u001b[0m, in \u001b[0;36mBaseMarshal.to_proto\u001b[1;34m(self, proto_type, value, strict)\u001b[0m\n\u001b[0;32m    232\u001b[0m     recursive_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(proto_type()\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_proto(recursive_type, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m--> 235\u001b[0m pb_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproto_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Sanity check: If we are in strict mode, did we get the value we want?\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pb_value, proto_type):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\marshal\\rules\\message.py:45\u001b[0m, in \u001b[0;36mMessageRule.to_proto\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_descriptor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mvalue)\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mValueError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m     38\u001b[0m         \u001b[38;5;66;03m# If we have a TypeError or Valueerror,\u001b[39;00m\n\u001b[0;32m     39\u001b[0m         \u001b[38;5;66;03m# try the slow path in case the error\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     43\u001b[0m         \u001b[38;5;66;03m#   See related issue: https://github.com/googleapis/python-api-core/issues/227.\u001b[39;00m\n\u001b[0;32m     44\u001b[0m         \u001b[38;5;66;03m# - a missing key issue due to nested struct. See: b/321905145.\u001b[39;00m\n\u001b[1;32m---> 45\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_pb\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\message.py:728\u001b[0m, in \u001b[0;36mMessage.__init__\u001b[1;34m(self, mapping, ignore_unknown_fields, **kwargs)\u001b[0m\n\u001b[0;32m    722\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    725\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnknown field for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, key)\n\u001b[0;32m    726\u001b[0m     )\n\u001b[1;32m--> 728\u001b[0m pb_value \u001b[38;5;241m=\u001b[39m \u001b[43mmarshal\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpb_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    730\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pb_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    731\u001b[0m     params[key] \u001b[38;5;241m=\u001b[39m pb_value\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\marshal\\marshal.py:235\u001b[0m, in \u001b[0;36mBaseMarshal.to_proto\u001b[1;34m(self, proto_type, value, strict)\u001b[0m\n\u001b[0;32m    232\u001b[0m     recursive_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(proto_type()\u001b[38;5;241m.\u001b[39mvalue)\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_proto(recursive_type, v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m--> 235\u001b[0m pb_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_rule\u001b[49m\u001b[43m(\u001b[49m\u001b[43mproto_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproto_type\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    237\u001b[0m \u001b[38;5;66;03m# Sanity check: If we are in strict mode, did we get the value we want?\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(pb_value, proto_type):\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\site-packages\\proto\\marshal\\rules\\enums.py:56\u001b[0m, in \u001b[0;36mEnumRule.to_proto\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;66;03m# If a string is provided that matches an enum value, coerce it\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;66;03m# to the enum value.\u001b[39;00m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_enum\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# We got a pure integer; pass it on.\u001b[39;00m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\gemini\\Lib\\enum.py:792\u001b[0m, in \u001b[0;36mEnumType.__getitem__\u001b[1;34m(cls, name)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mcls\u001b[39m, name):\n\u001b[0;32m    789\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    790\u001b[0m \u001b[38;5;124;03m    Return the member matching `name`.\u001b[39;00m\n\u001b[0;32m    791\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 792\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_member_map_\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'object'"
     ]
    }
   ],
   "source": [
    "# tool_config = tool_config_from_mode(\"auto\")\n",
    "\n",
    "response = model.generate_content(\"Given the inputted article rate it based on sensationalism from a score of 1 to 10.\\\n",
    "First, rate each chunk of the article based on the defined microfactors of sensationalism: \\\n",
    "1. Sensationalism Detection: Identify instances of sensationalism in titles and main content. \\\n",
    "2. Emotion Analysis: Assess the writing style for excessive emotionality or exaggeration.\\\n",
    "3. Linguistic Database Comparison: Match linguistic features against databases of both \\\n",
    "trusted and untrusted sources to ascertain reliability.\\\n",
    "This should be done paragraph by paragraph. \\\n",
    "Then, combine them into an overall score for sensationalism.\\\n",
    "Lastly please phrase overall score as 'Normal Prompting Overall sensationalism: {score}'\\\n",
    "where score is a float and the phrase should be in plain text with no bolding or italics\", stream=True, tools=tools, tool_config=tool_config)\n",
    "for chunk in response:\n",
    "    text_chunk = chunk.text\n",
    "    print(chunk.text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemini",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
